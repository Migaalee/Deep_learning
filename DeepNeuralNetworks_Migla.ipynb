{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepNeuralNetworks_Migla.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHVB119B36mXnbA93au12n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Migaalee/Deep_learning/blob/main/DeepNeuralNetworks_Migla.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2 - ADNE 2022\n",
        "\n",
        "## Deep neural networks using audio data \n",
        "\n",
        "### Aims\n",
        "\n",
        "The main aim of this project is optimise several deep neural networks for audio files. \n",
        "\n",
        "FeedForward neural network\n",
        "\n",
        "- Bla\n",
        "\n",
        "Recurrent neural network\n",
        "\n",
        "- bla\n",
        "\n",
        "Convolutional neural network \n",
        "\n",
        "- bla\n",
        "\n",
        "\n",
        "Transformers\n",
        "\n",
        "-bla\n",
        "\n",
        "\n",
        "### How this works\n",
        "This file is a [Jupyter Notebook](https://jupyter.org). \n",
        "It has instructions, and also code cells. The code cells are connected to Python, and you can run all of the code in a cell by pressing Play (▶) icon in the top bar, or pressing `shift + return`.\n",
        "The code libraries you should need are already installed.\n"
      ],
      "metadata": {
        "id": "Lz1I5CMWh54O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data pre-processing"
      ],
      "metadata": {
        "id": "X5yE7_Yeh6VX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import all required libraries"
      ],
      "metadata": {
        "id": "NljEabKQje0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#auth.authenticate_user()\n",
        "#gauth = GoogleAuth()\n",
        "#gauth.credentials = GoogleCredentials.get_application_default()\n",
        "#drive = GoogleDrive(gauth)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import io\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "sns.set()\n",
        "from tensorflow import keras\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from keras.constraints import maxnorm\n",
        "from tensorflow.keras.layers import Input, BatchNormalization, MaxPooling2D, Flatten, Conv2D, Dense, Activation, Dropout, concatenate, Reshape, UpSampling1D, Conv1D, MaxPooling1D\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from tensorflow.keras.layers import TimeDistributed,Input, Reshape, UpSampling1D, Conv1D\n",
        "from keras.layers.recurrent import LSTM\n",
        "import os\n",
        "from keras.layers import Embedding\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "#auth.authenticate_user()\n",
        "#gauth = GoogleAuth()\n",
        "#gauth.credentials = GoogleCredentials.get_application_default()\n",
        "#drive = GoogleDrive(gauth)\n",
        "from keras.layers import LeakyReLU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd1Nzs-BjfFE",
        "outputId": "3d044065-0099-4b53-ce27-83f487c2484c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auxilary functions"
      ],
      "metadata": {
        "id": "XyhCja_7lHYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_npy(fname):\n",
        "    \"\"\"fname should be a npy file; função auxiliar que vai ser usada pela função 'map' para ler o conteúdo de cada um dos ficheiros do fnames_dataset e criar um novo dataset com estes conteúdos.\"\"\"\n",
        "    fname = fname.decode()\n",
        "    recData = np.load(fname)\n",
        "    return recData.astype(np.float32)\n",
        "\n",
        "def cut_data(x):\n",
        "  N = tf.shape(x)[1]\n",
        "  r = tf.random.uniform(shape=[], maxval = (N - L), dtype = tf.dtypes.int32)\n",
        "  return x[:, N - r - L: N - r]"
      ],
      "metadata": {
        "id": "mXxLqA3hlHjM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import data for training, validation and testing"
      ],
      "metadata": {
        "id": "32iJDeLykfjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/adneDataAlunos/\")\n",
        "dir = './'\n",
        "list_train_files = glob.glob(dir + \"trainAlunos/\" + '*.npy')\n",
        "list_valid_files = glob.glob(dir + \"validacaoAlunos/\" + '*.npy')\n",
        "list_test_files = glob.glob(dir + \"testeAlunos/\" + '*.npy')\n",
        "data_train = tf.data.Dataset.from_tensor_slices(list_train_files) #creates a dataset with a separate element for each row of the input tensor, this will be important to put our different examples in separate tensors\n",
        "data_valid = tf.data.Dataset.from_tensor_slices(list_valid_files)\n",
        "data_test = tf.data.Dataset.from_tensor_slices(list_test_files)\n",
        "data_train = data_train.map(lambda x: tf.numpy_function(read_npy, [x], [tf.float32]))\n",
        "data_valid = data_valid.map(lambda x: tf.numpy_function(read_npy, [x], [tf.float32]))\n",
        "data_test = data_test.map(lambda x: tf.numpy_function(read_npy, [x], [tf.float32]))\n",
        "\n"
      ],
      "metadata": {
        "id": "eivSsME0kxjM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualisation of one tensor"
      ],
      "metadata": {
        "id": "VTwzFDdKlaqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "it = iter(data_train) #creates an object which can be iterated one element at a time\n",
        "ex = next(it) # returns the next item in an iterator\n",
        "ex\n",
        "#valid: shape=(2, 24002), train: shape=(2, 48000), test: shape=(2, 41325)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPlFz4-zlgty",
        "outputId": "9ab7b7b4-5949-4147-ef9d-7c5918565706"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 48000), dtype=float32, numpy=\n",
              " array([[ 199.,   47., -166., ...,   47.,   86.,  -66.],\n",
              "        [   4.,    4.,    4., ...,    4.,    4.,    4.]], dtype=float32)>,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex[0].shape\n",
        "aux=ex[0]\n",
        "plt.plot(aux[0,:5000]/1000)\n",
        "plt.plot(aux[1,:5000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "QHHNy-6ylvDT",
        "outputId": "5772b61a-11f6-4cc3-82a7-d360bf620a38"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6e513aecd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Segment data into pieces"
      ],
      "metadata": {
        "id": "sHZi7L97l0NC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L=2000\n",
        "data_train_cut = data_train.map(cut_data)\n",
        "data_test_cut = data_test.map(cut_data)\n",
        "data_valid_cut = data_valid.map(cut_data)"
      ],
      "metadata": {
        "id": "xmcpJ2e8l0WC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STFT transformation"
      ],
      "metadata": {
        "id": "z8ABTCB-mVDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### This STFT transformed data (cut into 2000) will be used for FFN"
      ],
      "metadata": {
        "id": "vLH5QmPc7N-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame_length=256\n",
        "frame_step =32\n",
        "data_train_stft = data_train_cut.map(lambda x: (tf.math.abs(tf.signal.stft(signals = x[0], frame_length = frame_length, frame_step = frame_step)), x[1]))\n",
        "data_test_stft = data_test_cut.map(lambda x: (tf.math.abs(tf.signal.stft(signals = x[0], frame_length = frame_length, frame_step = frame_step)), x[1]))\n",
        "data_valid_stft = data_valid_cut.map(lambda x: (tf.math.abs(tf.signal.stft(signals = x[0], frame_length = frame_length, frame_step = frame_step)), x[1]))"
      ],
      "metadata": {
        "id": "EQ37417-mVMh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  This STFT transformed data will be used for RNN, CNN, Transformers"
      ],
      "metadata": {
        "id": "S7CtVzWl7bjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_size_var_train = data_train.map(lambda x: ((tf.shape(x)[1], tf.math.abs(tf.signal.stft(signals = x[0], frame_length = frame_length, frame_step = frame_step))), x[1]))\n",
        "data_size_var_test = data_test.map(lambda x: ((tf.shape(x)[1], tf.math.abs(tf.signal.stft(signals = x[0], frame_length = frame_length, frame_step = frame_step))), x[1]))\n",
        "data_size_var_valid = data_valid.map(lambda x: ((tf.shape(x)[1], tf.math.abs(tf.signal.stft(signals = x[0], frame_length = frame_length, frame_step = frame_step))), x[1]))"
      ],
      "metadata": {
        "id": "kGT9UfUq623M"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define batch size for segmented data"
      ],
      "metadata": {
        "id": "XMUwWroOmnr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=2\n",
        "input_train = data_train_stft.batch(batch_size)\n",
        "input_test = data_test_stft.batch(batch_size)\n",
        "input_valid = data_valid_stft.batch(batch_size)"
      ],
      "metadata": {
        "id": "lKeGYQUFm1mR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define batch size and add padding for variable size data"
      ],
      "metadata": {
        "id": "Ib1-ZcIA7n8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "k = 129 #shape of x\n",
        "\n",
        "input_variable_train = data_size_var_train.padded_batch(batch_size, padded_shapes = (([], tf.TensorShape([None, k])), [None]))\n",
        "input_variable_test = data_size_var_test.padded_batch(batch_size, padded_shapes = (([], tf.TensorShape([None, k])), [None]))\n",
        "input_variable_valid = data_size_var_valid.padded_batch(batch_size, padded_shapes = (([], tf.TensorShape([None, k])), [None]))"
      ],
      "metadata": {
        "id": "uPA-6mw97oGU"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check input shape for cut data"
      ],
      "metadata": {
        "id": "6Xm4o8aZn7DK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "it1 = iter(input_variable_train)\n",
        "ex1 = next(it1)\n",
        "ex1 #input_train: shape=(2, 55, 129) data_size_var_train shape=(1493, 129), input_variable_train shape=(2, 1493, 129)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "977tYHXBn__w",
        "outputId": "d06ba208-2922-4b29-f984-ad1a98ed9bc4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((<tf.Tensor: shape=(2,), dtype=int32, numpy=array([48000,  7868], dtype=int32)>,\n",
              "  <tf.Tensor: shape=(2, 1493, 129), dtype=float32, numpy=\n",
              "  array([[[2.47430878e+02, 7.78422607e+03, 5.55400781e+03, ...,\n",
              "           3.46574059e+01, 6.97564087e+01, 4.06424255e+01],\n",
              "          [3.00475146e+03, 8.23914648e+03, 7.98841064e+03, ...,\n",
              "           4.47090950e+01, 6.33213692e+01, 8.73840332e+00],\n",
              "          [7.54572144e+02, 1.01712500e+04, 1.16385645e+04, ...,\n",
              "           5.70285950e+01, 6.35991859e+01, 2.09668884e+01],\n",
              "          ...,\n",
              "          [1.45487383e+04, 6.37698291e+03, 6.37474854e+03, ...,\n",
              "           4.22628021e+01, 2.13667717e+01, 9.26171875e+00],\n",
              "          [1.11278418e+04, 2.90557715e+03, 2.71550391e+03, ...,\n",
              "           5.27793503e+01, 2.77494526e+01, 1.46879883e+01],\n",
              "          [1.36672227e+04, 5.51294385e+03, 1.46977100e+03, ...,\n",
              "           5.72983055e+01, 4.12233925e+01, 2.30976562e+01]],\n",
              "  \n",
              "         [[5.97128809e+03, 1.19678047e+04, 1.26185166e+04, ...,\n",
              "           1.03938606e+02, 8.86179123e+01, 9.06081543e+01],\n",
              "          [4.22038281e+03, 1.06995664e+04, 9.94014648e+03, ...,\n",
              "           1.34850296e+02, 8.34196777e+01, 2.79343262e+01],\n",
              "          [1.00503006e+02, 8.84221680e+03, 7.30491602e+03, ...,\n",
              "           1.62162811e+02, 8.73747330e+01, 3.27359772e+01],\n",
              "          ...,\n",
              "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "           0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "           0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "           0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]], dtype=float32)>),\n",
              " <tf.Tensor: shape=(2, 48000), dtype=float32, numpy=\n",
              " array([[4., 4., 4., ..., 4., 4., 4.],\n",
              "        [4., 4., 4., ..., 0., 0., 0.]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define input shape"
      ],
      "metadata": {
        "id": "5OaYPeZeoeb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "itera = tf.compat.v1.data.Iterator.from_structure(tf.compat.v1.data.get_output_types(input_train),\n",
        "                                           tf.compat.v1.data.get_output_shapes(input_train))\n",
        "train_init_op = itera.make_initializer(input_train)\n",
        "\n",
        "features, labels = itera.get_next()\n",
        "sample = itera.get_next()\n",
        "sample\n",
        "input_shape = np.shape((sample)[0])[1:]\n",
        "print(input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8lUY9lPoelP",
        "outputId": "e2105668-57c9-420d-ebbe-3bf39374e070"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55, 129)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define variable input size"
      ],
      "metadata": {
        "id": "LN0YTX_s6lOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iterat = tf.compat.v1.data.Iterator.from_structure(tf.compat.v1.data.get_output_types(input_variable_train),\n",
        "                                           tf.compat.v1.data.get_output_shapes(input_variable_train))\n",
        "train_init_op2 = iterat.make_initializer(input_variable_train)\n",
        "\n",
        "features2, labels2 = iterat.get_next()\n",
        "sample2 = iterat.get_next()\n",
        "sample2\n",
        "#input_shape2 = np.shape((sample2)[1])[1] #48126\n",
        "#input_shape2 = np.shape((sample2)[1])[0] #2\n",
        "input_shape2 = np.shape((sample2)[1])[1:] #48126\n",
        "print(input_shape2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x3HJNMl6q6P",
        "outputId": "e4b41cf0-6532-4a79-ea4b-fdda17c612c3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48126,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K_O50p8Q6rkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FeedForward Neural network"
      ],
      "metadata": {
        "id": "jWG4Y0ZAh6dW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain what was tried"
      ],
      "metadata": {
        "id": "SYUbzBEjjnIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining hyperparameters"
      ],
      "metadata": {
        "id": "EX09n8nWrGcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 30 \n",
        "INIT_LR  = 0.001 #change to 0.001 after\n",
        "BS = 1 #batch size\n",
        "opt= SGD(learning_rate=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
        "opt2 = tf.optimizers.Adam(learning_rate = INIT_LR)"
      ],
      "metadata": {
        "id": "v8zJjQ1KrGwN"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "VRjNRTMErMa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feedforward_yes_upsampling_dense(opt, input_train, input_valid, input_test):\n",
        "    model = Sequential() #object of sequencial class\n",
        "    model.add(Flatten(input_shape=input_shape)) #we define the input shape, check shape after stft transformation\n",
        "    model.add(Dense(4096))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(Dense(2048))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(Dense(512))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(Dense(256))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(Dense(128)) \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(Dense(256))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.1))\n",
        "    #model.add(Dense(64)) \n",
        "   #model.add(BatchNormalization())\n",
        "    #model.add(LeakyReLU(alpha=0.1))\n",
        "    model.add(BatchNormalization()) # standardizes the inputs to a layer for each mini-batch. This has the effect of stabilizing the learning process and dramatically reducing the number of training epochs required to train deep networks\n",
        "    #output layer\n",
        "    model.add(Dense(100)) #because we have 4 y outputs, but also because it does not start at 0, we should reshape here to have an output of 10000 (2000x5)\n",
        "    model.add(Activation(\"softmax\"))\n",
        "\n",
        "    model.add(Reshape((20, 5))) #output is all cut data (segment size) and target numbers\n",
        "    model.add(UpSampling1D(100)) #tried 100 instead\n",
        "\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=['sparse_categorical_accuracy']) #multiclass classification problems, categorical crossentropy loss is the loss function of choice.\n",
        "\n",
        "    history = model.fit(input_train, validation_data=input_valid,\n",
        "                    batch_size=BS, \n",
        "                    epochs=NUM_EPOCHS)\n",
        "    # plotting the metrics\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.title('Sparse Crossentropy Loss')\n",
        "    plt.plot(history.history['loss'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_loss'], color='orange', label='val')\n",
        "\t\t# plot accuracy\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(history.history['sparse_categorical_accuracy'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_sparse_categorical_accuracy'], color='orange', label='val')\n",
        "    score = model.evaluate(input_test, verbose=0) #evaluate based on test dataset, which was not used for training and validation\n",
        "    return model.summary(), history, print('Loss using testing dataset=', score[0]), print('Accuracy using testing dataset=', score[1]) \n"
      ],
      "metadata": {
        "id": "bvllLJ924hGY"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the model"
      ],
      "metadata": {
        "id": "M5YB7aNcrRVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ffn=feedforward_yes_upsampling_dense(opt2, input_train, input_valid, input_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "tel17rGqtAmU",
        "outputId": "f14f4e9a-2438-4ca1-eb44-95c1fa7ccf35"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1250/1250 [==============================] - 196s 152ms/step - loss: 1.4782 - sparse_categorical_accuracy: 0.3253 - val_loss: 1.6170 - val_sparse_categorical_accuracy: 0.3543\n",
            "Epoch 2/30\n",
            "1250/1250 [==============================] - 205s 164ms/step - loss: 1.3724 - sparse_categorical_accuracy: 0.3601 - val_loss: 1.4348 - val_sparse_categorical_accuracy: 0.3712\n",
            "Epoch 3/30\n",
            "1250/1250 [==============================] - 150s 120ms/step - loss: 1.3568 - sparse_categorical_accuracy: 0.3608 - val_loss: 1.4227 - val_sparse_categorical_accuracy: 0.3963\n",
            "Epoch 4/30\n",
            "1250/1250 [==============================] - 159s 127ms/step - loss: 1.3485 - sparse_categorical_accuracy: 0.3655 - val_loss: 1.4397 - val_sparse_categorical_accuracy: 0.3858\n",
            "Epoch 5/30\n",
            "1250/1250 [==============================] - 170s 136ms/step - loss: 1.3479 - sparse_categorical_accuracy: 0.3614 - val_loss: 1.5482 - val_sparse_categorical_accuracy: 0.3532\n",
            "Epoch 6/30\n",
            " 187/1250 [===>..........................] - ETA: 2:17 - loss: 1.3431 - sparse_categorical_accuracy: 0.3639"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-3d4aa6f6f7aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mffn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeedforward_yes_upsampling_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-c53e4714a516>\u001b[0m in \u001b[0;36mfeedforward_yes_upsampling_dense\u001b[0;34m(opt, input_train, input_valid, input_test)\u001b[0m\n\u001b[1;32m     32\u001b[0m     history = model.fit(input_train, validation_data=input_valid,\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     epochs=NUM_EPOCHS)\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m# plotting the metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural network"
      ],
      "metadata": {
        "id": "unA1tqaqh6yV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "677tbHHoj64D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U9GPFOSRj7PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural network"
      ],
      "metadata": {
        "id": "Y5oyAKEYj-5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gSTAAUJ2EFuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(None,129),name='inputs')\n",
        "inputs_all = Input(shape=[], name='inputs2')\n",
        "inputs_variable=(inputs,inputs_all)\n",
        "\n",
        "inputs_variable[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr505Q5QEF68",
        "outputId": "98313940-457e-428a-d716-5f76817de955"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, None, 129) dtype=float32 (created by layer 'inputs')>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZivMuJr4kEBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KbN0v75iFfsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_variable(opt, inputs, input_variable_valid,input_variable_test):\n",
        "  inputs = Input(shape=(None,129),name='inputs')\n",
        "  inputs_L = Input(shape=[],name='inputs2')\n",
        "  layer_c = Conv1D(1024, 1, padding=\"same\")(inputs)\n",
        "  layer = Activation(\"LeakyReLU\")(layer_c)\n",
        "  layer = BatchNormalization(axis=-1)(layer)\n",
        "  layer = Dropout(0.25)(layer)\n",
        "  layer = Conv1D(512, 1, padding=\"same\")(layer)\n",
        "  layer = BatchNormalization(axis=-1)(layer)\n",
        "  layer = Dropout(0.1)(layer)\n",
        "  layer = Activation(\"LeakyReLU\")(layer)\n",
        "  layer = Conv1D(256, 1, padding=\"same\")(layer)\n",
        "  layer = BatchNormalization(axis=-1)(layer)\n",
        "  layer = Dropout(0.1)(layer)\n",
        "  layer = Activation(\"LeakyReLU\")(layer)\n",
        "  layer = Conv1D(128, 1, padding=\"same\")(layer)\n",
        "  layer = BatchNormalization(axis=-1)(layer)\n",
        "  layer = Dropout(0.1)(layer)\n",
        "  layer = Activation(\"LeakyReLU\")(layer)\n",
        "  layer = Conv1D(256, 1, padding=\"same\")(layer)\n",
        "  layer = BatchNormalization(axis=-1)(layer)\n",
        "  layer = Activation(\"LeakyReLU\")(layer)\n",
        "  layer = Dropout(0.1)(layer)\n",
        "  layer = MaxPooling1D(pool_size = 2)(layer)\n",
        "  #layer = Flatten()(layer)\n",
        "  #layer = Dropout(0.2)(layer)\n",
        "  layer = TimeDistributed(Dense(1500))(layer)\n",
        "  layer = Reshape((-1,5))(layer)\n",
        "  layer = UpSampling1D(size=15)(layer)\n",
        "  L = tf.cast(tf.reduce_max(inputs_L), tf.int32)\n",
        "  output = layer[:,:L]\n",
        "  model = Model(inputs = (inputs_L,inputs) , outputs=output)\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=[\"sparse_categorical_accuracy\"])\n",
        "  history = model.fit(input_variable_train, validation_data=input_variable_valid, batch_size=BS, epochs=NUM_EPOCHS, verbose=1)\n",
        "  # plotting the metrics\n",
        "  plt.subplot(2, 1, 1)\n",
        "  plt.title('Sparse Crossentropy Loss')\n",
        "  plt.plot(history.history['loss'], color='blue', label='train')\n",
        "  plt.plot(history.history['val_loss'], color='orange', label='val')\n",
        "\t# plot accuracy\n",
        "  plt.subplot(2, 1, 2)\n",
        "  plt.title('Classification Accuracy')\n",
        "  plt.plot(history.history['sparse_categorical_accuracy'], color='blue', label='train')\n",
        "  plt.plot(history.history['val_sparse_categorical_accuracy'], color='orange', label='val')\n",
        "  score = model.evaluate(input_variable_test, verbose=0) #evaluate based on test dataset, which was not used for training and validation\n",
        "  return model.summary(), history, print('Loss using testing dataset=', score[0]), print('Accuracy using testing dataset=', score[1]) "
      ],
      "metadata": {
        "id": "OZeBM9avkFhR"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run the model"
      ],
      "metadata": {
        "id": "uwkokUqVEVOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn= cnn_variable(opt2, input_variable_train, input_variable_valid,input_variable_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "Nz29sz-UEVXT",
        "outputId": "62965cb7-ab08-4a4b-ec44-52e5590f779d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "  76/1250 [>.............................] - ETA: 19:49 - loss: 5.3836 - sparse_categorical_accuracy: 0.2068"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-631580ec4cdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfunctional\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcnn_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_variable_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_variable_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_variable_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-76-98103ff7e939>\u001b[0m in \u001b[0;36mcnn_variable\u001b[0;34m(opt, inputs, input_variable_valid, input_variable_test)\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs_L\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sparse_categorical_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_variable_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_variable_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m   \u001b[0;31m# plotting the metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers"
      ],
      "metadata": {
        "id": "M7NHYaNNkHD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZT3T2MfYkKZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H6xe7OaokK77"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}